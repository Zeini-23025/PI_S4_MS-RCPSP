# ğŸ¤– Guide du Machine Learning

## ğŸ“‹ Vue d'ensemble

Le systÃ¨me MS-RCPSP utilise une approche de **Machine Learning multi-label** pour recommander automatiquement les meilleurs algorithmes d'ordonnancement pour chaque instance de projet.

## ğŸ§  Approche Binary Relevance

### **Principe**
Au lieu de prÃ©dire un seul algorithme optimal, le systÃ¨me :
1. **PrÃ©dit pour chaque algorithme** s'il est "bon" ou "mauvais"
2. **Recommande plusieurs algorithmes** simultanÃ©ment
3. **Augmente les chances** de trouver l'optimal

### **Architecture ML**
```
Instance de projet
     â†“
Extraction de 43 caractÃ©ristiques
     â†“
7 Classificateurs binaires (Random Forest)
â”œâ”€â”€ EST Classifier  â†’ EST recommandÃ© ? (Oui/Non)
â”œâ”€â”€ LFT Classifier  â†’ LFT recommandÃ© ? (Oui/Non)
â”œâ”€â”€ MSLF Classifier â†’ MSLF recommandÃ© ? (Oui/Non)
â”œâ”€â”€ SPT Classifier  â†’ SPT recommandÃ© ? (Oui/Non)
â”œâ”€â”€ LPT Classifier  â†’ LPT recommandÃ© ? (Oui/Non)
â”œâ”€â”€ FCFS Classifier â†’ FCFS recommandÃ© ? (Oui/Non)
â””â”€â”€ LST Classifier  â†’ LST recommandÃ© ? (Oui/Non)
     â†“
Liste d'algorithmes recommandÃ©s
```

## ğŸ“Š Extraction des caractÃ©ristiques

### **43 caractÃ©ristiques extraites**

#### 1. **CaractÃ©ristiques de base (7)**
```python
- num_jobs          # Nombre de tÃ¢ches
- num_resources     # Nombre de ressources  
- num_skills        # Nombre de compÃ©tences
- total_duration    # DurÃ©e totale des tÃ¢ches
- avg_duration      # DurÃ©e moyenne
- min_duration      # DurÃ©e minimale
- max_duration      # DurÃ©e maximale
```

#### 2. **DensitÃ©s et ratios (8)**
```python
- skill_density           # CompÃ©tences par tÃ¢che
- resource_utilization    # Utilisation des ressources
- skills_per_resource     # CompÃ©tences par ressource
- resources_per_job       # Ressources par tÃ¢che
- job_resource_ratio      # Ratio tÃ¢ches/ressources
- skill_resource_ratio    # Ratio compÃ©tences/ressources
- complexity_ratio        # ComplexitÃ© gÃ©nÃ©rale
- network_density         # DensitÃ© du rÃ©seau de prÃ©cÃ©dences
```

#### 3. **Statistiques avancÃ©es (12)**
```python
- duration_std, duration_variance  # VariabilitÃ© des durÃ©es
- workload_balance                 # Ã‰quilibrage des charges
- resource_contention             # Concurrence ressources
- skill_requirement_intensity     # IntensitÃ© compÃ©tences
- precedence_complexity          # ComplexitÃ© prÃ©cÃ©dences
- ... et autres mÃ©triques
```

#### 4. **MÃ©triques de rÃ©seau (8)**
```python
- precedence_density    # DensitÃ© des prÃ©cÃ©dences
- critical_path_length  # Longueur chemin critique
- parallelism_degree   # DegrÃ© de parallÃ©lisme
- bottleneck_intensity # IntensitÃ© goulots d'Ã©tranglement
- ... et autres
```

#### 5. **CaractÃ©ristiques de charge (8)**
```python
- peak_resource_demand     # Pic de demande ressource
- average_resource_load    # Charge moyenne
- resource_load_variance   # Variance de charge
- temporal_distribution    # Distribution temporelle
- ... et autres
```

### **Code d'extraction**
```python
def extract_features(instance_path):
    """Extrait 43 caractÃ©ristiques d'une instance"""
    
    # Chargement de l'instance
    jobs, resources, precedences = parse_instance(instance_path)
    
    # CaractÃ©ristiques de base
    features = {
        'num_jobs': len(jobs),
        'num_resources': len(resources),
        'num_skills': count_unique_skills(jobs),
        'total_duration': sum(job.duration for job in jobs),
        'avg_duration': np.mean([job.duration for job in jobs]),
        # ... 38 autres caractÃ©ristiques
    }
    
    return np.array(list(features.values()))
```

## ğŸ¯ CrÃ©ation des labels d'entraÃ®nement

### **StratÃ©gie de labeling**
```python
def create_labels(makespan_results, tolerance=0.1):
    """CrÃ©e les labels binaires avec tolÃ©rance"""
    
    # Trouver le makespan optimal
    optimal_makespan = min(makespan_results.values())
    
    # Label = 1 si dans la tolÃ©rance, 0 sinon
    labels = {}
    for algo, makespan in makespan_results.items():
        threshold = optimal_makespan * (1 + tolerance/100)
        labels[algo] = 1 if makespan <= threshold else 0
    
    return labels
```

### **TolÃ©rances testÃ©es**
- **0.1%** : TrÃ¨s stricte (sÃ©lection finale)
- **1.0%** : Stricte (alternative)
- **5.0%** : Permissive (tests)

### **Distribution des labels (tolÃ©rance 0.1%)**
```
EST  : 85% des instances (17/20)
LPT  : 90% des instances (18/20) 
LST  : 70% des instances (14/20)
SPT  : 50% des instances (10/20)
LFT  : 35% des instances (7/20)
MSLF : 30% des instances (6/20)
FCFS : 30% des instances (6/20)
```

## ğŸ”§ Configuration du modÃ¨le

### **Random Forest par classificateur**
```python
from sklearn.ensemble import RandomForestClassifier

classifier = RandomForestClassifier(
    n_estimators=100,      # 100 arbres
    random_state=42,       # ReproductibilitÃ©
    class_weight='balanced' # Ã‰quilibrage classes
)
```

### **Validation croisÃ©e**
```python
from sklearn.model_selection import cross_val_score

# 5-fold cross-validation
cv_scores = cross_val_score(classifier, X_train, y_train, cv=5)
accuracy = cv_scores.mean()
```

## ğŸ“ˆ Performance du modÃ¨le

### **MÃ©triques par algorithme**
```
Algorithme | Accuracy | Precision | Recall | F1-Score
-----------|----------|-----------|--------|----------
EST        | 100.0%   | 100.0%    | 100.0% | 100.0%
LPT        | 100.0%   | 100.0%    | 100.0% | 100.0%
LST        | 83.3%    | 100.0%    | 80.0%  | 88.9%
SPT        | 50.0%    | 50.0%     | 66.7%  | 57.1%
LFT        | 83.3%    | 100.0%    | 50.0%  | 66.7%
MSLF       | 83.3%    | 100.0%    | 50.0%  | 66.7%
FCFS       | 83.3%    | 100.0%    | 50.0%  | 66.7%
```

### **MÃ©triques globales**
```
Hamming Loss      : 16.7%
Exact Match Ratio : 50.0%
Subset Accuracy   : 100.0%
```

### **Performance en production**
```
Tests rÃ©ussis : 5/5 (100%)
IA correcte   : 5/5 (100%)
AmÃ©lioration  : 3.6% en moyenne
```

## ğŸ”„ Pipeline d'entraÃ®nement

### **1. PrÃ©paration des donnÃ©es**
```python
# 1. GÃ©nÃ©ration des donnÃ©es makespan
python3 makespan_calculator.py

# 2. Chargement et nettoyage
instances = load_instances_with_results("./resultats/makespan_details/")

# 3. Extraction des caractÃ©ristiques
X = np.array([extract_features(inst) for inst in instances])

# 4. CrÃ©ation des labels
y = np.array([create_labels(results) for results in makespan_results])
```

### **2. Division des donnÃ©es**
```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)
```

### **3. EntraÃ®nement**
```python
# Pour chaque algorithme
for i, algo in enumerate(['EST', 'LFT', 'MSLF', 'SPT', 'LPT', 'FCFS', 'LST']):
    
    # EntraÃ®ner le classificateur
    classifier = RandomForestClassifier()
    classifier.fit(X_train, y_train[:, i])
    
    # Valider
    accuracy = classifier.score(X_test, y_test[:, i])
    
    # Sauvegarder
    classifiers[algo] = classifier
```

### **4. Sauvegarde du modÃ¨le**
```python
import joblib

model_data = {
    'classifiers': classifiers,
    'feature_names': feature_names,
    'algorithm_names': algorithm_names,
    'training_stats': training_stats
}

joblib.dump(model_data, './resultats/binary_relevance_model.pkl')
```

## ğŸ¯ Utilisation du modÃ¨le

### **PrÃ©diction pour une nouvelle instance**
```python
# 1. Charger le modÃ¨le
model = joblib.load('./resultats/binary_relevance_model.pkl')

# 2. Extraire les caractÃ©ristiques
features = extract_features('nouvelle_instance.msrcp')

# 3. PrÃ©dire pour chaque algorithme
recommendations = []
for algo, classifier in model['classifiers'].items():
    if classifier.predict([features])[0] == 1:
        recommendations.append(algo)

# 4. RÃ©sultat
print(f"Algorithmes recommandÃ©s: {recommendations}")
```

### **Scores de confiance**
```python
# Obtenir les probabilitÃ©s
confidence_scores = {}
for algo, classifier in model['classifiers'].items():
    proba = classifier.predict_proba([features])[0]
    confidence_scores[algo] = proba[1]  # ProbabilitÃ© classe positive

# Trier par confiance
sorted_algos = sorted(confidence_scores.items(), 
                     key=lambda x: x[1], reverse=True)
```

## ğŸ”§ Optimisations et amÃ©liorations

### **RÃ©glage des hyperparamÃ¨tres**
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(
    RandomForestClassifier(),
    param_grid,
    cv=5,
    scoring='f1'
)
```

### **IngÃ©nierie des caractÃ©ristiques**
- **CaractÃ©ristiques dÃ©rivÃ©es** : Ratios, produits, diffÃ©rences
- **Transformations** : Log, sqrt, normalisation
- **SÃ©lection automatique** : Importance des features

### **Approches alternatives testÃ©es**
1. **Multi-class** : Un seul classificateur â†’ Moins performant
2. **Ensemble methods** : Combinaison de modÃ¨les â†’ ComplexitÃ© accrue
3. **Deep Learning** : RÃ©seaux de neurones â†’ Overfitting sur petit dataset

## ğŸ“Š Analyse des rÃ©sultats

### **Features les plus importantes**
```
1. num_jobs              (12.3%)
2. resource_utilization  (11.8%)
3. skill_density         (10.2%)
4. avg_duration          (9.7%)
5. complexity_ratio      (8.9%)
...
```

### **Patterns dÃ©couverts**
- **EST/LPT dominants** : Algorithmes les plus souvent optimaux
- **Projets complexes** : IA recommande plus d'algorithmes
- **Ressources limitÃ©es** : LST et MSLF privilÃ©giÃ©s
- **TÃ¢ches courtes** : SPT plus efficace

### **Cas d'Ã©chec analysÃ©s**
- **Instances parfaitement Ã©quilibrÃ©es** : Tous algorithmes Ã©quivalents
- **Contraintes trÃ¨s spÃ©cifiques** : Domaine non vu en entraÃ®nement
- **Taille de dataset** : Plus de donnÃ©es amÃ©liorerait les performances

## ğŸ¯ Perspective d'amÃ©lioration

### **DonnÃ©es**
- **Plus d'instances** : 100+ au lieu de 20
- **Instances diversifiÃ©es** : DiffÃ©rentes tailles et complexitÃ©s
- **Validation externe** : Benchmarks standards

### **ModÃ¨les**
- **Ensemble learning** : Combinaison de plusieurs approches
- **Transfer learning** : PrÃ©-entraÃ®nement sur domaines similaires
- **Online learning** : Mise Ã  jour continue du modÃ¨le

### **Features**
- **Features temporelles** : Ã‰volution dans le temps
- **Features contextuelles** : Type de projet, industrie
- **Features mÃ©ta** : PropriÃ©tÃ©s des algorithmes eux-mÃªmes
