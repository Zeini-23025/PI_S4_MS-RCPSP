#!/usr/bin/env python3
"""
üßπ NETTOYAGE ET VISUALISATION
=============================

Ce script supprime les fichiers non n√©cessaires et ajoute des graphiques
"""

import os
import json
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np
from pathlib import Path

def supprimer_fichiers_inutiles():
    """Supprime les fichiers redondants et non n√©cessaires"""
    
    print("üßπ NETTOYAGE DES FICHIERS NON N√âCESSAIRES")
    print("=" * 60)
    
    # Fichiers √† supprimer (redondants ou obsol√®tes)
    fichiers_a_supprimer = [
        "demo.py",  # Redondant avec demo_explication_simple.py
        "diagnostic.py",  # Remplac√© par solution_finale.py
        "exemple_ml.py",  # Redondant avec demo_ml_integration.py
        "msrcpsp_optimized.py",  # Version obsol√®te
        "improved_scheduler.py",  # Int√©gr√© dans msrcpsp_final.py
        "test_automatique.py",  # Remplac√© par test_massif_projets.py
        "demo_complete_system.py",  # Redondant
        "lire_pkl.py",  # Fonctionnalit√© int√©gr√©e ailleurs
    ]
    
    # Fichiers √† garder (essentiels)
    fichiers_essentiels = [
        "msrcpsp_final.py",  # Core scheduler
        "binary_relevance_msrcpsp.py",  # Core ML
        "makespan_calculator.py",  # Data generator
        "msrcpsp_complete.py",  # Batch processing
        "assistant_ml.py",  # Simple interface
        "solution_finale.py",  # Diagnostic tool
        "explication_algorithme_ml.py",  # Results viewer
        "detail_resultat_ml.py",  # Detailed analysis
        "test_massif_projets.py",  # Mass testing
        "demo_explication_simple.py",  # Simple demo
        "demo_ml_integration.py",  # ML integration demo
        "project.sh",  # Automation script
    ]
    
    fichiers_supprimes = 0
    
    for fichier in fichiers_a_supprimer:
        if os.path.exists(fichier):
            try:
                os.remove(fichier)
                print(f"üóëÔ∏è  Supprim√©: {fichier}")
                fichiers_supprimes += 1
            except Exception as e:
                print(f"‚ùå Erreur suppression {fichier}: {e}")
        else:
            print(f"‚ÑπÔ∏è  D√©j√† absent: {fichier}")
    
    print(f"\n‚úÖ {fichiers_supprimes} fichiers supprim√©s")
    
    # Afficher les fichiers restants
    print(f"\nüìÅ FICHIERS PYTHON RESTANTS:")
    python_files = [f for f in os.listdir('.') if f.endswith('.py')]
    for f in sorted(python_files):
        if f in fichiers_essentiels:
            print(f"   ‚úÖ {f} (essentiel)")
        else:
            print(f"   ‚ö†Ô∏è  {f} (√† v√©rifier)")

def creer_graphiques_makespan():
    """Cr√©e des graphiques pour les r√©sultats de makespan"""
    
    print("\nüìä CR√âATION DES GRAPHIQUES MAKESPAN")
    print("=" * 50)
    
    # Chercher les donn√©es de makespan
    resultats_dir = "./resultats"
    makespan_details_dir = os.path.join(resultats_dir, "makespan_details")
    
    if not os.path.exists(makespan_details_dir):
        print("‚ùå Dossier makespan_details non trouv√©")
        return
    
    # Cr√©er dossier pour graphiques
    graphiques_dir = os.path.join(resultats_dir, "graphiques")
    os.makedirs(graphiques_dir, exist_ok=True)
    
    # Lire tous les fichiers JSON de makespan
    all_data = []
    json_files = [f for f in os.listdir(makespan_details_dir) if f.endswith('.json')]
    
    print(f"üìÑ Lecture de {len(json_files)} fichiers de donn√©es...")
    
    for json_file in json_files:
        try:
            with open(os.path.join(makespan_details_dir, json_file), 'r') as f:
                data = json.load(f)
                all_data.append(data)
        except Exception as e:
            print(f"‚ùå Erreur lecture {json_file}: {e}")
    
    if not all_data:
        print("‚ùå Aucune donn√©e trouv√©e")
        return
    
    # Convertir en DataFrame
    df_list = []
    for data in all_data:
        instance = data['instance']
        for algo, result in data['results'].items():
            df_list.append({
                'Instance': instance,
                'Algorithme': algo,
                'Makespan': result['makespan']
            })
    
    df = pd.DataFrame(df_list)
    
    # Style des graphiques
    plt.style.use('default')
    sns.set_palette("husl")
    
    # 1. Graphique en barres - Performance moyenne par algorithme
    plt.figure(figsize=(12, 8))
    avg_makespan = df.groupby('Algorithme')['Makespan'].mean().sort_values()
    
    plt.subplot(2, 2, 1)
    bars = plt.bar(avg_makespan.index, avg_makespan.values, 
                   color=sns.color_palette("viridis", len(avg_makespan)))
    plt.title('Makespan Moyen par Algorithme', fontsize=14, fontweight='bold')
    plt.xlabel('Algorithme')
    plt.ylabel('Makespan Moyen (jours)')
    plt.xticks(rotation=45)
    
    # Ajouter les valeurs sur les barres
    for bar, value in zip(bars, avg_makespan.values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{value:.1f}', ha='center', va='bottom', fontweight='bold')
    
    # 2. Boxplot - Distribution des makespans
    plt.subplot(2, 2, 2)
    sns.boxplot(data=df, x='Algorithme', y='Makespan')
    plt.title('Distribution des Makespans', fontsize=14, fontweight='bold')
    plt.xticks(rotation=45)
    
    # 3. Heatmap - Comparaison par instance (√©chantillon)
    plt.subplot(2, 2, 3)
    # Prendre un √©chantillon d'instances pour la lisibilit√©
    sample_instances = df['Instance'].unique()[:15]
    df_sample = df[df['Instance'].isin(sample_instances)]
    pivot_data = df_sample.pivot(index='Instance', columns='Algorithme', values='Makespan')
    
    sns.heatmap(pivot_data, annot=True, fmt='.0f', cmap='RdYlGn_r', cbar_kws={'label': 'Makespan'})
    plt.title('Heatmap Makespans (√âchantillon)', fontsize=14, fontweight='bold')
    plt.xlabel('Algorithme')
    plt.ylabel('Instance')
    
    # 4. Graphique de victoires
    plt.subplot(2, 2, 4)
    victories = []
    for instance in df['Instance'].unique():
        instance_data = df[df['Instance'] == instance]
        best_algo = instance_data.loc[instance_data['Makespan'].idxmin(), 'Algorithme']
        victories.append(best_algo)
    
    victory_counts = pd.Series(victories).value_counts()
    colors = sns.color_palette("Set2", len(victory_counts))
    wedges, texts, autotexts = plt.pie(victory_counts.values, labels=victory_counts.index, 
                                      autopct='%1.1f%%', colors=colors, startangle=90)
    plt.title('Pourcentage de Victoires par Algorithme', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    
    # Sauvegarder
    graphique_path = os.path.join(graphiques_dir, "analyse_makespan.png")
    plt.savefig(graphique_path, dpi=300, bbox_inches='tight')
    print(f"‚úÖ Graphique sauv√©: {graphique_path}")
    
    plt.show()
    
    # Cr√©er un graphique s√©par√© pour les tendances
    plt.figure(figsize=(15, 6))
    
    # Graphique lin√©aire des performances
    for algo in df['Algorithme'].unique():
        algo_data = df[df['Algorithme'] == algo].sort_values('Instance')
        plt.plot(range(len(algo_data)), algo_data['Makespan'], 
                marker='o', label=algo, alpha=0.7, linewidth=2)
    
    plt.title('√âvolution des Makespans par Instance', fontsize=16, fontweight='bold')
    plt.xlabel('Index d\'Instance')
    plt.ylabel('Makespan (jours)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    
    # Sauvegarder
    tendance_path = os.path.join(graphiques_dir, "tendances_makespan.png")
    plt.savefig(tendance_path, dpi=300, bbox_inches='tight')
    print(f"‚úÖ Graphique sauv√©: {tendance_path}")
    
    plt.show()

def creer_graphiques_ml():
    """Cr√©e des graphiques pour les r√©sultats ML"""
    
    print("\nü§ñ CR√âATION DES GRAPHIQUES MACHINE LEARNING")
    print("=" * 60)
    
    # Chercher les r√©sultats ML
    resultats_ml_dir = "./resultats_ml"
    
    if not os.path.exists(resultats_ml_dir):
        print("‚ùå Dossier resultats_ml non trouv√©")
        return
    
    # Cr√©er dossier pour graphiques
    graphiques_dir = os.path.join("./resultats", "graphiques")
    os.makedirs(graphiques_dir, exist_ok=True)
    
    # Lire tous les r√©sultats ML
    ml_data = []
    json_files = [f for f in os.listdir(resultats_ml_dir) if f.endswith('.json')]
    
    print(f"üìÑ Lecture de {len(json_files)} r√©sultats ML...")
    
    for json_file in json_files:
        try:
            with open(os.path.join(resultats_ml_dir, json_file), 'r') as f:
                data = json.load(f)
                ml_data.append(data)
        except Exception as e:
            print(f"‚ùå Erreur lecture {json_file}: {e}")
    
    if not ml_data:
        print("‚ùå Aucun r√©sultat ML trouv√©")
        return
    
    # Analyser les donn√©es ML
    ia_predictions = []
    optimal_results = []
    all_results = []
    
    for data in ml_data:
        instance = data.get('instance', 'Unknown')
        ml_recommended = data.get('ml_recommended_algorithms', [])
        best_algo = data.get('best_algorithm', 'Unknown')
        best_makespan = data.get('best_makespan', 0)
        all_res = data.get('all_results', {})
        
        # V√©rifier si l'IA avait raison
        ia_correcte = best_algo in ml_recommended
        
        ia_predictions.append({
            'Instance': instance,
            'IA_Correcte': ia_correcte,
            'Meilleur_Algo': best_algo,
            'Makespan': best_makespan,
            'NB_Recommandes': len(ml_recommended)
        })
        
        # Analyser tous les r√©sultats
        for algo, result in all_res.items():
            makespan = result.get('makespan', 0)
            all_results.append({
                'Instance': instance,
                'Algorithme': algo,
                'Makespan': makespan,
                'Est_Recommande': algo in ml_recommended,
                'Est_Optimal': algo == best_algo
            })
    
    df_predictions = pd.DataFrame(ia_predictions)
    df_all = pd.DataFrame(all_results)
    
    # Cr√©er les graphiques ML
    plt.figure(figsize=(15, 10))
    
    # 1. Taux de succ√®s de l'IA
    plt.subplot(2, 3, 1)
    success_rate = df_predictions['IA_Correcte'].mean() * 100
    labels = ['Succ√®s IA', '√âchec IA']
    sizes = [success_rate, 100 - success_rate]
    colors = ['#28a745', '#dc3545']
    
    wedges, texts, autotexts = plt.pie(sizes, labels=labels, autopct='%1.1f%%', 
                                      colors=colors, startangle=90)
    plt.title(f'Taux de Succ√®s de l\'IA\n({success_rate:.1f}%)', 
              fontsize=14, fontweight='bold')
    
    # 2. Performance des algorithmes recommand√©s vs non recommand√©s
    plt.subplot(2, 3, 2)
    recommande_data = df_all[df_all['Est_Recommande']]['Makespan']
    non_recommande_data = df_all[~df_all['Est_Recommande']]['Makespan']
    
    plt.boxplot([recommande_data, non_recommande_data], 
                labels=['Recommand√©s\npar IA', 'Non\nRecommand√©s'])
    plt.title('Performance: Recommand√©s vs Non-Recommand√©s', 
              fontsize=14, fontweight='bold')
    plt.ylabel('Makespan (jours)')
    
    # 3. Fr√©quence des algorithmes recommand√©s
    plt.subplot(2, 3, 3)
    algo_recommendations = []
    for data in ml_data:
        algo_recommendations.extend(data.get('ml_recommended_algorithms', []))
    
    recommendation_counts = pd.Series(algo_recommendations).value_counts()
    bars = plt.bar(recommendation_counts.index, recommendation_counts.values,
                   color=sns.color_palette("Set3", len(recommendation_counts)))
    plt.title('Fr√©quence des Recommandations IA', fontsize=14, fontweight='bold')
    plt.xlabel('Algorithme')
    plt.ylabel('Nombre de Recommandations')
    plt.xticks(rotation=45)
    
    # Ajouter valeurs sur barres
    for bar, value in zip(bars, recommendation_counts.values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                str(value), ha='center', va='bottom', fontweight='bold')
    
    # 4. Heatmap de confusion IA
    plt.subplot(2, 3, 4)
    optimal_algos = df_predictions['Meilleur_Algo'].value_counts()
    confusion_matrix = np.zeros((len(optimal_algos), 2))
    
    for i, algo in enumerate(optimal_algos.index):
        successes = len(df_predictions[(df_predictions['Meilleur_Algo'] == algo) & 
                                     (df_predictions['IA_Correcte'] == True)])
        failures = len(df_predictions[(df_predictions['Meilleur_Algo'] == algo) & 
                                    (df_predictions['IA_Correcte'] == False)])
        confusion_matrix[i] = [successes, failures]
    
    sns.heatmap(confusion_matrix, annot=True, fmt='.0f', 
                xticklabels=['IA Succ√®s', 'IA √âchec'],
                yticklabels=optimal_algos.index,
                cmap='RdYlGn', cbar_kws={'label': 'Nombre de cas'})
    plt.title('Matrice de Performance IA', fontsize=14, fontweight='bold')
    
    # 5. Distribution des makespans par statut
    plt.subplot(2, 3, 5)
    optimal_makespans = df_all[df_all['Est_Optimal']]['Makespan']
    recommande_makespans = df_all[df_all['Est_Recommande'] & ~df_all['Est_Optimal']]['Makespan']
    autres_makespans = df_all[~df_all['Est_Recommande'] & ~df_all['Est_Optimal']]['Makespan']
    
    plt.hist([optimal_makespans, recommande_makespans, autres_makespans], 
             bins=15, alpha=0.7, 
             label=['Optimal', 'Recommand√© (non-optimal)', 'Autres'],
             color=['gold', 'lightblue', 'lightcoral'])
    plt.title('Distribution des Makespans', fontsize=14, fontweight='bold')
    plt.xlabel('Makespan (jours)')
    plt.ylabel('Fr√©quence')
    plt.legend()
    
    # 6. Am√©lioration apport√©e par l'IA
    plt.subplot(2, 3, 6)
    ameliorations = []
    for data in ml_data:
        all_res = data.get('all_results', {})
        if len(all_res) > 1:
            makespans = [res.get('makespan', float('inf')) for res in all_res.values()]
            best_makespan = min(makespans)
            worst_makespan = max([ms for ms in makespans if ms != float('inf')])
            if worst_makespan != best_makespan:
                improvement = ((worst_makespan - best_makespan) / worst_makespan) * 100
                ameliorations.append(improvement)
    
    if ameliorations:
        plt.hist(ameliorations, bins=10, alpha=0.7, color='green', edgecolor='black')
        plt.title(f'Am√©lioration par l\'IA\n(Moyenne: {np.mean(ameliorations):.1f}%)', 
                  fontsize=14, fontweight='bold')
        plt.xlabel('Am√©lioration (%)')
        plt.ylabel('Nombre d\'Instances')
    
    plt.tight_layout()
    
    # Sauvegarder
    ml_graphique_path = os.path.join(graphiques_dir, "analyse_ml.png")
    plt.savefig(ml_graphique_path, dpi=300, bbox_inches='tight')
    print(f"‚úÖ Graphique ML sauv√©: {ml_graphique_path}")
    
    plt.show()
    
    # Cr√©er un rapport de performance IA
    print(f"\nüìä RAPPORT DE PERFORMANCE IA:")
    print(f"   üéØ Taux de succ√®s: {success_rate:.1f}%")
    print(f"   üìä Instances test√©es: {len(df_predictions)}")
    if ameliorations:
        print(f"   üìà Am√©lioration moyenne: {np.mean(ameliorations):.1f}%")
    
    # Sauvegarder le rapport
    rapport_path = os.path.join(graphiques_dir, "rapport_performance_ia.json")
    rapport = {
        "taux_succes_ia": success_rate,
        "instances_testees": len(df_predictions),
        "amelioration_moyenne": np.mean(ameliorations) if ameliorations else 0,
        "algorithmes_les_plus_recommandes": recommendation_counts.to_dict(),
        "algorithmes_les_plus_optimaux": optimal_algos.to_dict()
    }
    
    with open(rapport_path, 'w', encoding='utf-8') as f:
        json.dump(rapport, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Rapport sauv√©: {rapport_path}")

def installer_dependances():
    """Installe les d√©pendances n√©cessaires pour les graphiques"""
    
    print("üì¶ INSTALLATION DES D√âPENDANCES")
    print("=" * 40)
    
    try:
        import matplotlib
        import seaborn
        import pandas
        import numpy
        print("‚úÖ Toutes les d√©pendances sont d√©j√† install√©es")
        return True
    except ImportError as e:
        print(f"‚ùå D√©pendance manquante: {e}")
        print("üí° Installation automatique...")
        
        import subprocess
        import sys
        
        packages = ['matplotlib', 'seaborn', 'pandas', 'numpy']
        
        for package in packages:
            try:
                subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])
                print(f"‚úÖ {package} install√©")
            except subprocess.CalledProcessError:
                print(f"‚ùå √âchec installation {package}")
                return False
        
        return True

def main():
    """Fonction principale"""
    
    print("üé® NETTOYAGE ET VISUALISATION MS-RCPSP")
    print("=" * 60)
    
    # Menu
    print("1. üßπ Supprimer fichiers non n√©cessaires")
    print("2. üìä Cr√©er graphiques makespan")
    print("3. ü§ñ Cr√©er graphiques ML")
    print("4. üéØ Tout faire (recommand√©)")
    print("0. ‚ùå Quitter")
    
    choix = input("\nVotre choix (0-4): ").strip()
    
    if choix == "0":
        print("üëã Au revoir!")
        return
    
    # Installer les d√©pendances si n√©cessaire
    if choix in ["2", "3", "4"]:
        if not installer_dependances():
            print("‚ùå Impossible de cr√©er les graphiques sans les d√©pendances")
            return
    
    if choix == "1":
        supprimer_fichiers_inutiles()
    elif choix == "2":
        creer_graphiques_makespan()
    elif choix == "3":
        creer_graphiques_ml()
    elif choix == "4":
        supprimer_fichiers_inutiles()
        creer_graphiques_makespan()
        creer_graphiques_ml()
        
        print(f"\nüéä TERMIN√â !")
        print("‚úÖ Fichiers nettoy√©s")
        print("‚úÖ Graphiques cr√©√©s")
        print("üìÅ Consultez le dossier resultats/graphiques/")
    else:
        print("‚ùå Choix invalide")

if __name__ == "__main__":
    main()
