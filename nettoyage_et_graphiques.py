#!/usr/bin/env python3
"""
ğŸ§¹ NETTOYAGE ET VISUALISATION
=============================

Ce script supprime les fichiers non nÃ©cessaires et ajoute des graphiques
"""

import os
import json
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np
from pathlib import Path

def supprimer_fichiers_inutiles():
    """Supprime les fichiers redondants et non nÃ©cessaires"""
    
    print("ğŸ§¹ NETTOYAGE DES FICHIERS NON NÃ‰CESSAIRES")
    print("=" * 60)
    
    # Fichiers Ã  supprimer (redondants ou obsolÃ¨tes)
    fichiers_a_supprimer = [
        "demo.py",  # Redondant avec demo_explication_simple.py
        "diagnostic.py",  # RemplacÃ© par solution_finale.py
        "exemple_ml.py",  # Redondant avec demo_ml_integration.py
        "msrcpsp_optimized.py",  # Version obsolÃ¨te
        "improved_scheduler.py",  # IntÃ©grÃ© dans msrcpsp_final.py
        "test_automatique.py",  # RemplacÃ© par test_massif_projets.py
        "demo_complete_system.py",  # Redondant
        "lire_pkl.py",  # FonctionnalitÃ© intÃ©grÃ©e ailleurs
    ]
    
    # Fichiers Ã  garder (essentiels)
    fichiers_essentiels = [
        "msrcpsp_final.py",  # Core scheduler
        "binary_relevance_msrcpsp.py",  # Core ML
        "makespan_calculator.py",  # Data generator
        "msrcpsp_complete.py",  # Batch processing
        "assistant_ml.py",  # Simple interface
        "solution_finale.py",  # Diagnostic tool
        "explication_algorithme_ml.py",  # Results viewer
        "detail_resultat_ml.py",  # Detailed analysis
        "test_massif_projets.py",  # Mass testing
        "demo_explication_simple.py",  # Simple demo
        "demo_ml_integration.py",  # ML integration demo
        "project.sh",  # Automation script
    ]
    
    fichiers_supprimes = 0
    
    for fichier in fichiers_a_supprimer:
        if os.path.exists(fichier):
            try:
                os.remove(fichier)
                print(f"ğŸ—‘ï¸  SupprimÃ©: {fichier}")
                fichiers_supprimes += 1
            except Exception as e:
                print(f"âŒ Erreur suppression {fichier}: {e}")
        else:
            print(f"â„¹ï¸  DÃ©jÃ  absent: {fichier}")
    
    print(f"\nâœ… {fichiers_supprimes} fichiers supprimÃ©s")
    
    # Afficher les fichiers restants
    print(f"\nğŸ“ FICHIERS PYTHON RESTANTS:")
    python_files = [f for f in os.listdir('.') if f.endswith('.py')]
    for f in sorted(python_files):
        if f in fichiers_essentiels:
            print(f"   âœ… {f} (essentiel)")
        else:
            print(f"   âš ï¸  {f} (Ã  vÃ©rifier)")

def creer_graphiques_makespan():
    """CrÃ©e des graphiques pour les rÃ©sultats de makespan"""
    
    print("\nğŸ“Š CRÃ‰ATION DES GRAPHIQUES MAKESPAN")
    print("=" * 50)
    
    # Chercher les donnÃ©es de makespan
    resultats_dir = "./resultats"
    makespan_details_dir = os.path.join(resultats_dir, "makespan_details")
    
    if not os.path.exists(makespan_details_dir):
        print("âŒ Dossier makespan_details non trouvÃ©")
        return
    
    # CrÃ©er dossier pour graphiques
    graphiques_dir = os.path.join(resultats_dir, "graphiques")
    os.makedirs(graphiques_dir, exist_ok=True)
    
    # Lire tous les fichiers JSON de makespan
    all_data = []
    json_files = [f for f in os.listdir(makespan_details_dir) if f.endswith('.json')]
    
    print(f"ğŸ“„ Lecture de {len(json_files)} fichiers de donnÃ©es...")
    
    for json_file in json_files:
        try:
            with open(os.path.join(makespan_details_dir, json_file), 'r') as f:
                data = json.load(f)
                all_data.append(data)
        except Exception as e:
            print(f"âŒ Erreur lecture {json_file}: {e}")
    
    if not all_data:
        print("âŒ Aucune donnÃ©e trouvÃ©e")
        return
    
    # Convertir en DataFrame
    df_list = []
    for data in all_data:
        instance = data['instance']
        for algo, result in data['results'].items():
            df_list.append({
                'Instance': instance,
                'Algorithme': algo,
                'Makespan': result['makespan']
            })
    
    df = pd.DataFrame(df_list)
    
    # Style des graphiques
    plt.style.use('default')
    sns.set_palette("husl")
    
    # 1. Graphique en barres - Performance moyenne par algorithme
    plt.figure(figsize=(12, 8))
    avg_makespan = df.groupby('Algorithme')['Makespan'].mean().sort_values()
    
    plt.subplot(2, 2, 1)
    bars = plt.bar(avg_makespan.index, avg_makespan.values, 
                   color=sns.color_palette("viridis", len(avg_makespan)))
    plt.title('Makespan Moyen par Algorithme', fontsize=14, fontweight='bold')
    plt.xlabel('Algorithme')
    plt.ylabel('Makespan Moyen (jours)')
    plt.xticks(rotation=45)
    
    # Ajouter les valeurs sur les barres
    for bar, value in zip(bars, avg_makespan.values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{value:.1f}', ha='center', va='bottom', fontweight='bold')
    
    # 2. Boxplot - Distribution des makespans
    plt.subplot(2, 2, 2)
    sns.boxplot(data=df, x='Algorithme', y='Makespan')
    plt.title('Distribution des Makespans', fontsize=14, fontweight='bold')
    plt.xticks(rotation=45)
    
    # 3. Heatmap - Comparaison par instance (Ã©chantillon)
    plt.subplot(2, 2, 3)
    # Prendre un Ã©chantillon d'instances pour la lisibilitÃ©
    sample_instances = df['Instance'].unique()[:15]
    df_sample = df[df['Instance'].isin(sample_instances)]
    pivot_data = df_sample.pivot(index='Instance', columns='Algorithme', values='Makespan')
    
    sns.heatmap(pivot_data, annot=True, fmt='.0f', cmap='RdYlGn_r', cbar_kws={'label': 'Makespan'})
    plt.title('Heatmap Makespans (Ã‰chantillon)', fontsize=14, fontweight='bold')
    plt.xlabel('Algorithme')
    plt.ylabel('Instance')
    
    # 4. Graphique de victoires
    plt.subplot(2, 2, 4)
    victories = []
    for instance in df['Instance'].unique():
        instance_data = df[df['Instance'] == instance]
        best_algo = instance_data.loc[instance_data['Makespan'].idxmin(), 'Algorithme']
        victories.append(best_algo)
    
    victory_counts = pd.Series(victories).value_counts()
    colors = sns.color_palette("Set2", len(victory_counts))
    wedges, texts, autotexts = plt.pie(victory_counts.values, labels=victory_counts.index, 
                                      autopct='%1.1f%%', colors=colors, startangle=90)
    plt.title('Pourcentage de Victoires par Algorithme', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    
    # Sauvegarder
    graphique_path = os.path.join(graphiques_dir, "analyse_makespan.png")
    plt.savefig(graphique_path, dpi=300, bbox_inches='tight')
    print(f"âœ… Graphique sauvÃ©: {graphique_path}")
    
    plt.show()
    
    # CrÃ©er un graphique sÃ©parÃ© pour les tendances
    plt.figure(figsize=(15, 6))
    
    # Graphique linÃ©aire des performances
    for algo in df['Algorithme'].unique():
        algo_data = df[df['Algorithme'] == algo].sort_values('Instance')
        plt.plot(range(len(algo_data)), algo_data['Makespan'], 
                marker='o', label=algo, alpha=0.7, linewidth=2)
    
    plt.title('Ã‰volution des Makespans par Instance', fontsize=16, fontweight='bold')
    plt.xlabel('Index d\'Instance')
    plt.ylabel('Makespan (jours)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    
    # Sauvegarder
    tendance_path = os.path.join(graphiques_dir, "tendances_makespan.png")
    plt.savefig(tendance_path, dpi=300, bbox_inches='tight')
    print(f"âœ… Graphique sauvÃ©: {tendance_path}")
    
    plt.show()

def creer_graphiques_ml():
    """CrÃ©e des graphiques pour les rÃ©sultats ML"""
    
    print("\nğŸ¤– CRÃ‰ATION DES GRAPHIQUES MACHINE LEARNING")
    print("=" * 60)
    
    # Chercher les rÃ©sultats ML
    resultats_ml_dir = "./resultats_ml"
    
    if not os.path.exists(resultats_ml_dir):
        print("âŒ Dossier resultats_ml non trouvÃ©")
        return
    
    # CrÃ©er dossier pour graphiques
    graphiques_dir = os.path.join("./resultats", "graphiques")
    os.makedirs(graphiques_dir, exist_ok=True)
    
    # Lire tous les rÃ©sultats ML
    ml_data = []
    json_files = [f for f in os.listdir(resultats_ml_dir) if f.endswith('.json')]
    
    print(f"ğŸ“„ Lecture de {len(json_files)} rÃ©sultats ML...")
    
    for json_file in json_files:
        try:
            with open(os.path.join(resultats_ml_dir, json_file), 'r') as f:
                data = json.load(f)
                ml_data.append(data)
        except Exception as e:
            print(f"âŒ Erreur lecture {json_file}: {e}")
    
    if not ml_data:
        print("âŒ Aucun rÃ©sultat ML trouvÃ©")
        return
    
    # Analyser les donnÃ©es ML
    ia_predictions = []
    optimal_results = []
    all_results = []
    
    for data in ml_data:
        instance = data.get('instance', 'Unknown')
        ml_recommended = data.get('ml_recommended_algorithms', [])
        best_algo = data.get('best_algorithm', 'Unknown')
        best_makespan = data.get('best_makespan', 0)
        all_res = data.get('all_results', {})
        
        # VÃ©rifier si l'IA avait raison
        ia_correcte = best_algo in ml_recommended
        
        ia_predictions.append({
            'Instance': instance,
            'IA_Correcte': ia_correcte,
            'Meilleur_Algo': best_algo,
            'Makespan': best_makespan,
            'NB_Recommandes': len(ml_recommended)
        })
        
        # Analyser tous les rÃ©sultats
        for algo, result in all_res.items():
            makespan = result.get('makespan', 0)
            all_results.append({
                'Instance': instance,
                'Algorithme': algo,
                'Makespan': makespan,
                'Est_Recommande': algo in ml_recommended,
                'Est_Optimal': algo == best_algo
            })
    
    df_predictions = pd.DataFrame(ia_predictions)
    df_all = pd.DataFrame(all_results)
    
    # CrÃ©er les graphiques ML
    plt.figure(figsize=(15, 10))
    
    # 1. Taux de succÃ¨s de l'IA
    plt.subplot(2, 3, 1)
    success_rate = df_predictions['IA_Correcte'].mean() * 100
    labels = ['SuccÃ¨s IA', 'Ã‰chec IA']
    sizes = [success_rate, 100 - success_rate]
    colors = ['#28a745', '#dc3545']
    
    wedges, texts, autotexts = plt.pie(sizes, labels=labels, autopct='%1.1f%%', 
                                      colors=colors, startangle=90)
    plt.title(f'Taux de SuccÃ¨s de l\'IA\n({success_rate:.1f}%)', 
              fontsize=14, fontweight='bold')
    
    # 2. Performance des algorithmes recommandÃ©s vs non recommandÃ©s
    plt.subplot(2, 3, 2)
    recommande_data = df_all[df_all['Est_Recommande']]['Makespan']
    non_recommande_data = df_all[~df_all['Est_Recommande']]['Makespan']
    
    plt.boxplot([recommande_data, non_recommande_data], 
                labels=['RecommandÃ©s\npar IA', 'Non\nRecommandÃ©s'])
    plt.title('Performance: RecommandÃ©s vs Non-RecommandÃ©s', 
              fontsize=14, fontweight='bold')
    plt.ylabel('Makespan (jours)')
    
    # 3. FrÃ©quence des algorithmes recommandÃ©s
    plt.subplot(2, 3, 3)
    algo_recommendations = []
    for data in ml_data:
        algo_recommendations.extend(data.get('ml_recommended_algorithms', []))
    
    recommendation_counts = pd.Series(algo_recommendations).value_counts()
    bars = plt.bar(recommendation_counts.index, recommendation_counts.values,
                   color=sns.color_palette("Set3", len(recommendation_counts)))
    plt.title('FrÃ©quence des Recommandations IA', fontsize=14, fontweight='bold')
    plt.xlabel('Algorithme')
    plt.ylabel('Nombre de Recommandations')
    plt.xticks(rotation=45)
    
    # Ajouter valeurs sur barres
    for bar, value in zip(bars, recommendation_counts.values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                str(value), ha='center', va='bottom', fontweight='bold')
    
    # 4. Heatmap de confusion IA
    plt.subplot(2, 3, 4)
    optimal_algos = df_predictions['Meilleur_Algo'].value_counts()
    confusion_matrix = np.zeros((len(optimal_algos), 2))
    
    for i, algo in enumerate(optimal_algos.index):
        successes = len(df_predictions[(df_predictions['Meilleur_Algo'] == algo) & 
                                     (df_predictions['IA_Correcte'] == True)])
        failures = len(df_predictions[(df_predictions['Meilleur_Algo'] == algo) & 
                                    (df_predictions['IA_Correcte'] == False)])
        confusion_matrix[i] = [successes, failures]
    
    sns.heatmap(confusion_matrix, annot=True, fmt='.0f', 
                xticklabels=['IA SuccÃ¨s', 'IA Ã‰chec'],
                yticklabels=optimal_algos.index,
                cmap='RdYlGn', cbar_kws={'label': 'Nombre de cas'})
    plt.title('Matrice de Performance IA', fontsize=14, fontweight='bold')
    
    # 5. Distribution des makespans par statut
    plt.subplot(2, 3, 5)
    optimal_makespans = df_all[df_all['Est_Optimal']]['Makespan']
    recommande_makespans = df_all[df_all['Est_Recommande'] & ~df_all['Est_Optimal']]['Makespan']
    autres_makespans = df_all[~df_all['Est_Recommande'] & ~df_all['Est_Optimal']]['Makespan']
    
    plt.hist([optimal_makespans, recommande_makespans, autres_makespans], 
             bins=15, alpha=0.7, 
             label=['Optimal', 'RecommandÃ© (non-optimal)', 'Autres'],
             color=['gold', 'lightblue', 'lightcoral'])
    plt.title('Distribution des Makespans', fontsize=14, fontweight='bold')
    plt.xlabel('Makespan (jours)')
    plt.ylabel('FrÃ©quence')
    plt.legend()
    
    # 6. AmÃ©lioration apportÃ©e par l'IA
    plt.subplot(2, 3, 6)
    ameliorations = []
    for data in ml_data:
        all_res = data.get('all_results', {})
        if len(all_res) > 1:
            makespans = [res.get('makespan', float('inf')) for res in all_res.values()]
            best_makespan = min(makespans)
            worst_makespan = max([ms for ms in makespans if ms != float('inf')])
            if worst_makespan != best_makespan:
                improvement = ((worst_makespan - best_makespan) / worst_makespan) * 100
                ameliorations.append(improvement)
    
    if ameliorations:
        plt.hist(ameliorations, bins=10, alpha=0.7, color='green', edgecolor='black')
        plt.title(f'AmÃ©lioration par l\'IA\n(Moyenne: {np.mean(ameliorations):.1f}%)', 
                  fontsize=14, fontweight='bold')
        plt.xlabel('AmÃ©lioration (%)')
        plt.ylabel('Nombre d\'Instances')
    
    plt.tight_layout()
    
    # Sauvegarder
    ml_graphique_path = os.path.join(graphiques_dir, "analyse_ml.png")
    plt.savefig(ml_graphique_path, dpi=300, bbox_inches='tight')
    print(f"âœ… Graphique ML sauvÃ©: {ml_graphique_path}")
    
    plt.show()
    
    # CrÃ©er un rapport de performance IA
    print(f"\nğŸ“Š RAPPORT DE PERFORMANCE IA:")
    print(f"   ğŸ¯ Taux de succÃ¨s: {success_rate:.1f}%")
    print(f"   ğŸ“Š Instances testÃ©es: {len(df_predictions)}")
    if ameliorations:
        print(f"   ğŸ“ˆ AmÃ©lioration moyenne: {np.mean(ameliorations):.1f}%")
    
    # Sauvegarder le rapport
    rapport_path = os.path.join(graphiques_dir, "rapport_performance_ia.json")
    rapport = {
        "taux_succes_ia": success_rate,
        "instances_testees": len(df_predictions),
        "amelioration_moyenne": np.mean(ameliorations) if ameliorations else 0,
        "algorithmes_les_plus_recommandes": recommendation_counts.to_dict(),
        "algorithmes_les_plus_optimaux": optimal_algos.to_dict()
    }
    
    with open(rapport_path, 'w', encoding='utf-8') as f:
        json.dump(rapport, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Rapport sauvÃ©: {rapport_path}")

def installer_dependances():
    """Installe les dÃ©pendances nÃ©cessaires pour les graphiques"""
    
    print("ğŸ“¦ INSTALLATION DES DÃ‰PENDANCES")
    print("=" * 40)
    
    try:
        import matplotlib
        import seaborn
        import pandas
        import numpy
        print("âœ… Toutes les dÃ©pendances sont dÃ©jÃ  installÃ©es")
        return True
    except ImportError as e:
        print(f"âŒ DÃ©pendance manquante: {e}")
        print("ğŸ’¡ Installation automatique...")
        
        import subprocess
        import sys
        
        packages = ['matplotlib', 'seaborn', 'pandas', 'numpy']
        
        for package in packages:
            try:
                subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])
                print(f"âœ… {package} installÃ©")
            except subprocess.CalledProcessError:
                print(f"âŒ Ã‰chec installation {package}")
                return False
        
        return True

def main():
    """Fonction principale"""
    
    print("ğŸ¨ NETTOYAGE ET VISUALISATION MS-RCPSP")
    print("=" * 60)
    
    # Menu
    print("1. ğŸ§¹ Supprimer fichiers non nÃ©cessaires")
    print("2. ğŸ“Š CrÃ©er graphiques makespan")
    print("3. ğŸ¤– CrÃ©er graphiques ML")
    print("4. ğŸ¯ Tout faire (recommandÃ©)")
    print("0. âŒ Quitter")
    
    choix = input("\nVotre choix (0-4): ").strip()
    
    if choix == "0":
        print("ğŸ‘‹ Au revoir!")
        return
    
    # Installer les dÃ©pendances si nÃ©cessaire
    if choix in ["2", "3", "4"]:
        if not installer_dependances():
            print("âŒ Impossible de crÃ©er les graphiques sans les dÃ©pendances")
            return
    
    if choix == "1":
        supprimer_fichiers_inutiles()
    elif choix == "2":
        creer_graphiques_makespan()
    elif choix == "3":
        creer_graphiques_ml()
    elif choix == "4":
        supprimer_fichiers_inutiles()
        creer_graphiques_makespan()
        creer_graphiques_ml()
        
        print(f"\nğŸŠ TERMINÃ‰ !")
        print("âœ… Fichiers nettoyÃ©s")
        print("âœ… Graphiques crÃ©Ã©s")
        print("ğŸ“ Consultez le dossier resultats/graphiques/")
    else:
        print("âŒ Choix invalide")

if __name__ == "__main__":
    main()
