#!/usr/bin/env python3
"""
ğŸ§ª TESTEUR MASSIF - TESTER TOUS LES PROJETS
==========================================

Ce script teste l'IA sur TOUS les projets disponibles
"""

import os
import time
import json
from binary_relevance_msrcpsp import MLIntegratedMSRCPSP

def tester_tous_les_projets():
    """Teste l'IA sur tous les projets disponibles"""
    
    print("ğŸ§ª TESTEUR MASSIF - TOUS LES PROJETS")
    print("=" * 60)
    
    # VÃ©rifier le modÃ¨le
    model_path = "./resultats/binary_relevance_model.pkl"
    if not os.path.exists(model_path):
        print("âŒ ModÃ¨le ML non trouvÃ© !")
        print("ğŸ’¡ ExÃ©cutez './project.sh' pour crÃ©er le modÃ¨le")
        return
    
    # CrÃ©er l'instance ML
    try:
        ml_msrcpsp = MLIntegratedMSRCPSP(model_path)
        print("âœ… ModÃ¨le ML chargÃ© avec succÃ¨s")
    except Exception as e:
        print(f"âŒ Erreur lors du chargement du modÃ¨le : {e}")
        return
    
    # Lister tous les projets
    instances_dir = "./Instances"
    if not os.path.exists(instances_dir):
        print(f"âŒ Dossier {instances_dir} non trouvÃ© !")
        return
    
    all_instances = [f for f in os.listdir(instances_dir) if f.endswith('.msrcp')]
    all_instances.sort()
    
    print(f"ğŸ“ Dossier source : {instances_dir}")
    print(f"ğŸ“Š Nombre total de projets : {len(all_instances)}")
    
    # Demander combien tester
    print("\nğŸ¯ COMBIEN DE PROJETS TESTER ?")
    print("1. ğŸš€ Test rapide (10 projets)")
    print("2. ğŸ“Š Test moyen (50 projets)")
    print("3. ğŸ—ï¸ Test large (100 projets)")
    print("4. ğŸŒ TOUS LES PROJETS ! (peut prendre du temps)")
    print("5. ğŸ¯ Nombre personnalisÃ©")
    
    choix = input("\nVotre choix (1-5) : ").strip()
    
    if choix == "1":
        nb_projets = 10
    elif choix == "2":
        nb_projets = 50
    elif choix == "3":
        nb_projets = 100
    elif choix == "4":
        nb_projets = len(all_instances)
    elif choix == "5":
        try:
            nb_projets = int(input("Nombre de projets Ã  tester : "))
        except:
            nb_projets = 10
    else:
        nb_projets = 10
    
    # Limiter au nombre disponible
    nb_projets = min(nb_projets, len(all_instances))
    test_instances = all_instances[:nb_projets]
    
    print(f"\nğŸ¯ Test sur {nb_projets} projets")
    print("=" * 40)
    
    # Dossier de sortie
    output_dir = "./resultats_ml"
    os.makedirs(output_dir, exist_ok=True)
    
    # Variables de suivi
    resultats_complets = []
    reussites = 0
    echecs = 0
    temps_total = 0
    ia_correcte = 0
    
    print("ğŸ”„ DÃ‰MARRAGE DU TEST...")
    temps_debut = time.time()
    
    for i, filename in enumerate(test_instances):
        instance_path = os.path.join(instances_dir, filename)
        
        print(f"\n[{i+1:3d}/{nb_projets}] {filename}")
        
        try:
            temps_debut_instance = time.time()
            
            # RÃ©soudre avec ML
            result = ml_msrcpsp.solve_with_ml_guidance(instance_path, output_dir)
            
            temps_fin_instance = time.time()
            temps_instance = temps_fin_instance - temps_debut_instance
            temps_total += temps_instance
            
            if result and 'best_makespan' in result:
                makespan = result['best_makespan']
                best_algo = result['best_algorithm']
                recommended = result['ml_recommended_algorithms']
                
                # VÃ©rifier si l'IA avait raison
                ia_succes = best_algo in recommended
                if ia_succes:
                    ia_correcte += 1
                
                status_ia = "âœ…" if ia_succes else "âŒ"
                
                print(f"  {status_ia} Optimal: {best_algo} = {makespan} jours ({temps_instance:.1f}s)")
                print(f"     ğŸ¤– IA: {recommended}")
                
                # Sauver le rÃ©sultat
                resultats_complets.append({
                    'instance': filename,
                    'best_algorithm': best_algo,
                    'best_makespan': makespan,
                    'ml_recommended': recommended,
                    'ia_correcte': ia_succes,
                    'temps': temps_instance
                })
                
                reussites += 1
            else:
                print(f"  âŒ Ã‰chec de rÃ©solution")
                echecs += 1
                
        except Exception as e:
            print(f"  âŒ Erreur: {str(e)[:50]}...")
            echecs += 1
        
        # Affichage du progrÃ¨s toutes les 10 instances
        if (i + 1) % 10 == 0:
            temps_ecoule = time.time() - temps_debut
            vitesse = (i + 1) / temps_ecoule
            temps_restant = (nb_projets - (i + 1)) / vitesse if vitesse > 0 else 0
            
            print(f"\nğŸ“Š PROGRÃˆS: {i+1}/{nb_projets} ({(i+1)/nb_projets*100:.1f}%)")
            print(f"   â±ï¸ Vitesse: {vitesse:.1f} projets/seconde")
            print(f"   â° Temps restant estimÃ©: {temps_restant/60:.1f} minutes")
    
    # RÃ©sultats finaux
    temps_total_reel = time.time() - temps_debut
    
    print("\n" + "="*60)
    print("ğŸŠ RÃ‰SULTATS FINAUX DU TEST MASSIF")
    print("="*60)
    
    print(f"ğŸ“Š STATISTIQUES GÃ‰NÃ‰RALES:")
    print(f"   â€¢ Projets testÃ©s     : {nb_projets}")
    print(f"   â€¢ RÃ©ussites         : {reussites}")
    print(f"   â€¢ Ã‰checs            : {echecs}")
    print(f"   â€¢ Taux de rÃ©ussite  : {reussites/nb_projets*100:.1f}%")
    
    print(f"\nğŸ¤– PERFORMANCE DE L'IA:")
    if reussites > 0:
        print(f"   â€¢ IA correcte       : {ia_correcte}/{reussites}")
        print(f"   â€¢ Taux de prÃ©cision : {ia_correcte/reussites*100:.1f}%")
    
    print(f"\nâ±ï¸ PERFORMANCE TEMPORELLE:")
    print(f"   â€¢ Temps total       : {temps_total_reel/60:.1f} minutes")
    print(f"   â€¢ Temps moyen/projet: {temps_total_reel/nb_projets:.2f} secondes")
    
    # Analyse des algorithmes
    if resultats_complets:
        print(f"\nğŸ† ALGORITHMES LES PLUS PERFORMANTS:")
        algo_count = {}
        makespans = []
        
        for res in resultats_complets:
            algo = res['best_algorithm']
            algo_count[algo] = algo_count.get(algo, 0) + 1
            makespans.append(res['best_makespan'])
        
        for algo, count in sorted(algo_count.items(), key=lambda x: x[1], reverse=True):
            print(f"   â€¢ {algo}: {count} fois ({count/len(resultats_complets)*100:.1f}%)")
        
        print(f"\nğŸ“Š MAKESPANS:")
        print(f"   â€¢ Minimum : {min(makespans):.0f} jours")
        print(f"   â€¢ Maximum : {max(makespans):.0f} jours")
        print(f"   â€¢ Moyenne : {sum(makespans)/len(makespans):.1f} jours")
    
    # Sauvegarder le rapport complet
    rapport_path = os.path.join(output_dir, "rapport_test_massif.json")
    rapport_data = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "nb_projets_testes": nb_projets,
        "reussites": reussites,
        "echecs": echecs,
        "ia_correcte": ia_correcte,
        "temps_total_minutes": temps_total_reel/60,
        "temps_moyen_seconde": temps_total_reel/nb_projets if nb_projets > 0 else 0,
        "resultats_detailles": resultats_complets
    }
    
    try:
        with open(rapport_path, 'w', encoding='utf-8') as f:
            json.dump(rapport_data, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ“„ Rapport sauvÃ© : {rapport_path}")
    except Exception as e:
        print(f"âŒ Erreur sauvegarde rapport : {e}")
    
    print(f"\nğŸ“ Tous les rÃ©sultats dans : {output_dir}")
    print(f"ğŸ“„ Fichiers JSON crÃ©Ã©s : {len([f for f in os.listdir(output_dir) if f.endswith('.json')])}")
    
    print("\nğŸ¯ COMMANDES POUR ANALYSER LES RÃ‰SULTATS:")
    print("   python3 explication_algorithme_ml.py  # Voir tous les rÃ©sultats")
    print("   python3 detail_resultat_ml.py         # Analyse dÃ©taillÃ©e")
    
    return resultats_complets

def test_rapide_echantillon():
    """Test rapide sur un Ã©chantillon reprÃ©sentatif"""
    
    print("ğŸš€ TEST RAPIDE - Ã‰CHANTILLON REPRÃ‰SENTATIF")
    print("=" * 60)
    
    # SÃ©lectionner des projets variÃ©s
    instances_dir = "./Instances"
    all_instances = [f for f in os.listdir(instances_dir) if f.endswith('.msrcp')]
    
    # Prendre des projets Ã  intervalles rÃ©guliers pour avoir de la variÃ©tÃ©
    step = max(1, len(all_instances) // 20)  # ~20 projets reprÃ©sentatifs
    echantillon = all_instances[::step][:20]
    
    print(f"ğŸ“Š SÃ©lection de {len(echantillon)} projets reprÃ©sentatifs")
    print(f"ğŸ“ Sur un total de {len(all_instances)} projets disponibles")
    
    # Lancer le test
    model_path = "./resultats/binary_relevance_model.pkl"
    if not os.path.exists(model_path):
        print("âŒ ModÃ¨le non trouvÃ© ! Lancez './project.sh'")
        return
    
    try:
        ml_msrcpsp = MLIntegratedMSRCPSP(model_path)
        output_dir = "./resultats_ml"
        
        reussites = 0
        ia_correcte = 0
        
        for i, filename in enumerate(echantillon):
            instance_path = os.path.join(instances_dir, filename)
            print(f"[{i+1:2d}/20] {filename[:20]}...", end=" ")
            
            try:
                result = ml_msrcpsp.solve_with_ml_guidance(instance_path, output_dir)
                if result and 'best_makespan' in result:
                    best_algo = result['best_algorithm']
                    recommended = result['ml_recommended_algorithms']
                    ia_succes = best_algo in recommended
                    
                    if ia_succes:
                        ia_correcte += 1
                    
                    status = "âœ…" if ia_succes else "âŒ"
                    print(f"{status} {best_algo}")
                    reussites += 1
                else:
                    print("âŒ Ã‰chec")
            except:
                print("âŒ Erreur")
        
        print(f"\nğŸ“Š RÃ‰SULTAT RAPIDE:")
        print(f"   RÃ©ussites: {reussites}/20")
        print(f"   PrÃ©cision IA: {ia_correcte}/{reussites} ({ia_correcte/reussites*100:.1f}%)")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")

def main():
    """Menu principal"""
    
    print("ğŸ§ª TESTEUR DE PROJETS - MENU PRINCIPAL")
    print("=" * 50)
    print("1. ğŸš€ Test rapide (20 projets reprÃ©sentatifs)")
    print("2. ğŸ—ï¸ Test personnalisÃ© (choisir le nombre)")
    print("3. â“ Aide")
    
    choix = input("\nVotre choix (1-3) : ").strip()
    
    if choix == "1":
        test_rapide_echantillon()
    elif choix == "2":
        tester_tous_les_projets()
    elif choix == "3":
        print("""
ğŸ¯ AIDE - COMMENT UTILISER CE TESTEUR

ğŸ“‹ OBJECTIF :
   Tester l'Intelligence Artificielle sur de nombreux projets
   pour mesurer sa performance rÃ©elle

ğŸš€ TEST RAPIDE :
   â€¢ SÃ©lectionne 20 projets variÃ©s automatiquement
   â€¢ Rapide (~2-3 minutes)
   â€¢ Donne une bonne idÃ©e de la performance

ğŸ—ï¸ TEST PERSONNALISÃ‰ :
   â€¢ Vous choisissez combien de projets tester
   â€¢ Plus de projets = rÃ©sultats plus prÃ©cis
   â€¢ Peut prendre du temps pour de gros volumes

ğŸ“Š RÃ‰SULTATS :
   â€¢ Taux de rÃ©ussite de l'IA
   â€¢ Algorithmes les plus performants
   â€¢ Temps de calcul moyen
   â€¢ Rapport dÃ©taillÃ© en JSON

ğŸ’¡ CONSEILS :
   â€¢ Commencez par le test rapide
   â€¢ Si satisfait, lancez un test plus large
   â€¢ Les rÃ©sultats sont sauvÃ©s dans resultats_ml/
""")
    else:
        test_rapide_echantillon()

if __name__ == "__main__":
    main()
